{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf93c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.34.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3~=2.5.0 in c:\\source\\team-3rd\\tempfitcrawler\\venv\\lib\\site-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
      "Collecting trio~=0.30.0 (from selenium)\n",
      "  Using cached trio-0.30.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.12.2 (from selenium)\n",
      "  Using cached trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2025.6.15 in c:\\source\\team-3rd\\tempfitcrawler\\venv\\lib\\site-packages (from selenium) (2025.7.14)\n",
      "Requirement already satisfied: typing_extensions~=4.14.0 in c:\\source\\team-3rd\\tempfitcrawler\\venv\\lib\\site-packages (from selenium) (4.14.1)\n",
      "Collecting websocket-client~=1.8.0 (from selenium)\n",
      "  Using cached websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting attrs>=23.2.0 (from trio~=0.30.0->selenium)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting sortedcontainers (from trio~=0.30.0->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in c:\\source\\team-3rd\\tempfitcrawler\\venv\\lib\\site-packages (from trio~=0.30.0->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.30.0->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting sniffio>=1.3.0 (from trio~=0.30.0->selenium)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\source\\team-3rd\\tempfitcrawler\\venv\\lib\\site-packages (from trio~=0.30.0->selenium) (1.17.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.12.2->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]~=2.5.0->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pycparser in c:\\source\\team-3rd\\tempfitcrawler\\venv\\lib\\site-packages (from cffi>=1.14->trio~=0.30.0->selenium) (2.22)\n",
      "Collecting h11<1,>=0.9.0 (from wsproto>=0.14->trio-websocket~=0.12.2->selenium)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Downloading selenium-4.34.2-py3-none-any.whl (9.4 MB)\n",
      "   ---------------------------------------- 0.0/9.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 9.4/9.4 MB 49.9 MB/s eta 0:00:00\n",
      "Using cached trio-0.30.0-py3-none-any.whl (499 kB)\n",
      "Using cached trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: sortedcontainers, websocket-client, sniffio, pysocks, h11, attrs, wsproto, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed attrs-25.3.0 h11-0.16.0 outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.34.2 sniffio-1.3.1 sortedcontainers-2.4.0 trio-0.30.0 trio-websocket-0.12.2 websocket-client-1.8.0 wsproto-1.2.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# !pip install oracledb\n",
    "# !pip install requests beautifulsoup4\n",
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22533b01",
   "metadata": {},
   "source": [
    "### 남성 의상 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d8ad7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import oracledb\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# DB 연결 설정\n",
    "\n",
    "conn = oracledb.connect(\n",
    "    user='coordi',\n",
    "    password='12345',\n",
    "    dsn='localhost/xe'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# INSERT SQL 남성\n",
    "insert_sql = \"\"\"\n",
    "    INSERT INTO products_male(\n",
    "        product_id,\n",
    "        category_id,\n",
    "        brand_name,\n",
    "        product_name,\n",
    "        image_url,\n",
    "        link_url\n",
    "    ) VALUES (\n",
    "        :productId,\n",
    "        :categoryId,\n",
    "        :brandName,\n",
    "        :productName,\n",
    "        :imageUrl,\n",
    "        :linkUrl\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "search_keywords = [\"민소매\",\"반소매\",\"헨리넥 반소매\",\"피케/카라티\",\"반팔 니트/스웨터\",\"반팔 셔츠\",\"반소매 가디건\",\"얇은 셔츠\",\"린넨 셔츠\",\"긴소매\",\"셔츠\",\"얇은 니트/스웨터\",\"얇은 가디건\",\"바람막이\",\"가디건\",\"니트/스웨터\",\"후드티\",\"맨투맨\",\"블레이저\",\"트렌치코트\",\"가죽자켓\",\"울코트\",\"패딩코트\",\"패딩\",\"면반바지\",\"데님 반바지\",\"린넨 팬츠\",\"화이트 데님\",\"얇은 데님\",\"얇은 슬랙스\",\"데님\",\"코튼 팬츠\",\"슬랙스\",\"스웨트팬츠\",\"두꺼운 데님\",\"울팬츠\",\"샌들/슬리퍼\",\"크록스\",\"스니커즈\",\"운동화\",\"구두\",\"부츠/워커\",\"패딩/퍼\"]\n",
    "local_id = 1\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')  # 백그라운드 실행\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "for idx, keyword in enumerate(search_keywords, 1):\n",
    "    driver.get('http://www.musinsa.com/')\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, 'sc-dzagxs-2').click()\n",
    "    search = driver.find_element(By.CLASS_NAME, 'sc-97s1c6-2')\n",
    "    search.send_keys(keyword, Keys.ENTER)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 성별 선택\n",
    "    male_btn = driver.find_element(By.XPATH, \"//button[@data-filter-type='남성']\")\n",
    "    if \"text-body_13px_semi\" not in male_btn.get_attribute(\"class\"):\n",
    "        male_btn.click()\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # 페이지를 세 번 스크롤하여 콘텐츠 로드\n",
    "    def scroll(times=3, pause=3):\n",
    "        for _ in range(times):\n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            time.sleep(pause)\n",
    "    scroll(3, 3)\n",
    "\n",
    "    # 데이터 수집\n",
    "    soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "\n",
    "    # 전체 상품 영역 가져오기\n",
    "    products = soup.find_all(\"div\", class_=\"sc-d36st-1\")\n",
    "\n",
    "    product_all = []\n",
    "\n",
    "    for product in products:\n",
    "        img = product.select_one(\"img\")\n",
    "        # 상품경로\n",
    "        detail = product.select_one(\"a\") \n",
    "        link_url = detail.get(\"href\")   \n",
    "        # product_id = detail.get(\"data-item-id\")   \n",
    "        product_id = local_id\n",
    "        local_id += 1\n",
    "        # 브랜드명\n",
    "        brand_name = product.select_one(\"a > span\").text.strip()\n",
    "        # 상품명\n",
    "        product_name = product.select_one('div.sc-cMuefe.jIlLeV > a.gtm-select-item > span').text.strip()\n",
    "        # 이미지경로\n",
    "        image_url = img.get('src').split(\"?\")[0]\n",
    "        # print(product_id,image_url,product_name,link_url,brand_name)\n",
    "\n",
    "        product_all.append([product_id,idx,brand_name,product_name,image_url,link_url])\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    # DB 코드\n",
    "    cursor.executemany(\"INSERT INTO products_male(product_id,category_id,brand_name,product_name,image_url,link_url) VALUES (:1, :2, :3, :4, :5, :6)\",product_all)\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5e7343",
   "metadata": {},
   "source": [
    "### 여성 의상 데이터 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fb65384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "import oracledb\n",
    "\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# DB 연결 설정\n",
    "conn = oracledb.connect(\n",
    "    user='coordi',\n",
    "    password='12345',\n",
    "    dsn='localhost/xe'\n",
    ")\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# INSERT SQL 여성\n",
    "insert_sql = \"\"\"\n",
    "    INSERT INTO products_female(\n",
    "        product_id,\n",
    "        category_id,\n",
    "        brand_name,\n",
    "        product_name,\n",
    "        image_url,\n",
    "        link_url\n",
    "    ) VALUES (\n",
    "        :productId,\n",
    "        :categoryId,\n",
    "        :brandName,\n",
    "        :productName,\n",
    "        :imageUrl,\n",
    "        :linkUrl\n",
    "    )\n",
    "\"\"\"\n",
    "\n",
    "search_keywords = [\"나시\",\"반소매\",\"헨리넥 반소매\",\"반소매 블라우스\",\"피케/카라 원피스\",\"여름 가디건\",\"원피스\",\"맥시드레스\",\"반팔 니트/스웨터\",\"긴소매\",\"블라우스\",\"얇은 니트/스웨터\",\"얇은 가디건\",\"바람막이\",\"가디건\",\"니트/스웨터\",\"후드티\",\"블레이저\",\"트렌치코트\",\"가죽자켓\",\"울코트\",\"패딩\",\"반바지\",\"숏스커트\",\"린넨 팬츠\",\"화이트 데님\",\"얇은 데님\",\"얇은 슬랙스\",\"롱스커트\",\"데님\",\"코튼 팬츠\",\"슬랙스\",\"스웨트팬츠\",\"두꺼운 데님\",\"울팬츠\",\"샌들/슬리퍼\",\"크록스\",\"스니커즈\",\"오픈토힐\",\"운동화\",\"구두\",\"앵클부츠\",\"부츠\",\"패딩/퍼\"]\n",
    "local_id = 1\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "# options.add_argument('--headless')  # 백그라운드 실행\n",
    "driver = webdriver.Chrome(options=options)\n",
    "driver.maximize_window()\n",
    "\n",
    "for idx, keyword in enumerate(search_keywords, 1):\n",
    "    driver.get('http://www.musinsa.com/')\n",
    "\n",
    "    driver.find_element(By.CLASS_NAME, 'sc-dzagxs-2').click()\n",
    "    search = driver.find_element(By.CLASS_NAME, 'sc-97s1c6-2')\n",
    "    search.send_keys(keyword, Keys.ENTER)\n",
    "    time.sleep(2)\n",
    "\n",
    "    # 성별 선택\n",
    "    female_btn = driver.find_element(By.XPATH, \"//button[@data-filter-type='여성']\")\n",
    "    if \"text-body_13px_semi\" not in female_btn.get_attribute(\"class\"):\n",
    "        female_btn.click()\n",
    "        time.sleep(2)\n",
    "\n",
    "    # 페이지를 두 번 스크롤하여 콘텐츠 로드\n",
    "    def scroll(times=2, pause=2):\n",
    "        for _ in range(times):\n",
    "            driver.execute_script('window.scrollTo(0, document.body.scrollHeight);')\n",
    "            time.sleep(pause)\n",
    "    scroll(2, 2)\n",
    "\n",
    "    # 데이터 수집\n",
    "    soup = BeautifulSoup(driver.page_source,\"html.parser\")\n",
    "\n",
    "    # 전체 상품 영역 가져오기\n",
    "    products = soup.find_all(\"div\", class_=\"sc-d36st-1\")\n",
    "\n",
    "    product_all = []\n",
    "\n",
    "    for product in products:\n",
    "        img = product.select_one(\"img\")\n",
    "        # 상품경로\n",
    "        detail = product.select_one(\"a\") \n",
    "        link_url = detail.get(\"href\")   \n",
    "        # product_id = detail.get(\"data-item-id\")   \n",
    "        product_id = local_id\n",
    "        local_id += 1\n",
    "        # 브랜드명\n",
    "        brand_name = product.select_one(\"a > span\").text.strip()\n",
    "        # 상품명\n",
    "        product_name = product.select_one('div.sc-cMuefe.jIlLeV > a.gtm-select-item > span').text.strip()\n",
    "        # 이미지경로\n",
    "        image_url = img.get('src').split(\"?\")[0]\n",
    "        # print(product_id,image_url,product_name,link_url,brand_name)\n",
    "\n",
    "        product_all.append([product_id,idx,brand_name,product_name,image_url,link_url])\n",
    "\n",
    "    time.sleep(3)\n",
    "\n",
    "    # DB 코드\n",
    "    cursor.executemany(\"INSERT INTO products_female(product_id,category_id,brand_name,product_name,image_url,link_url) VALUES (:1, :2, :3, :4, :5, :6)\",product_all)\n",
    "    conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
